{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minimal-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/in-divye.singh/Documents/Projects/MIC_predictor\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "warming-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import ntpath\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from scipy import signal\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "velvet-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brief-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIDUES = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "            'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "# Kyte & Doolittle {kd} index of hydrophobicity\n",
    "HP = {'A': 1.8, 'R':-4.5, 'N':-3.5, 'D':-3.5, 'C': 2.5,\n",
    "      'Q':-3.5, 'E':-3.5, 'G':-0.4, 'H':-3.2, 'I': 4.5,\n",
    "      'L': 3.8, 'K':-3.9, 'M': 1.9, 'F': 2.8, 'P':-1.6,\n",
    "      'S':-0.8, 'T':-0.7, 'W':-0.9, 'Y':-1.3, 'V': 4.2, 'U': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "yellow-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_signal(sig, window=25):\n",
    "    win = signal.hann(window)\n",
    "    sig = signal.convolve(sig, win, mode='same') / sum(win)\n",
    "    return sig\n",
    "\n",
    "\n",
    "def average(l):\n",
    "    return sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "psychological-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydroPhobicIndex:\n",
    "    def __init__(self, hpilist):\n",
    "        self.hpilist = hpilist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bibliographic-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hydrophobic(df):\n",
    "    for index, row in df.iterrows():\n",
    "        hpilst = pd.Series(list(row['Seq'])).map(HP).tolist()\n",
    "        df.loc[index, 'HydroPhobicIndex'] = HydroPhobicIndex(hpilst)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ordinary-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hydrophobic_features(df):\n",
    "    df = hydrophobic(df)\n",
    "    hpi0, hpi1, hpi2, hpi3, hpi4, hpi5 = list(), list(), list(), list(), list(), list() \n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    #for index, row in self.df.iterrows():\n",
    "        sw = convolve_signal(row['HydroPhobicIndex'].hpilist, window=30)\n",
    "        hpi0.append(sum(i < -1.5 for i in sw) / len(sw))\n",
    "        # self.df.loc[index, 'hpi_<-1.5_frac'] = hpi\n",
    "        hpi1.append(sum(i < -2.0 for i in sw) / len(sw))\n",
    "        # self.df.loc[index, 'hpi_<-2.0_frac'] = hpi\n",
    "        hpi2.append(sum(i < -2.5 for i in sw) / len(sw))\n",
    "        # self.df.loc[index, 'hpi_<-2.5_frac'] = hpi\n",
    "        hpi3.append(sum(i < -1.5 for i in sw))\n",
    "        # self.df.loc[index, 'hpi_<-1.5'] = hpi\n",
    "        hpi4.append( sum(i < -2.0 for i in sw))\n",
    "        # self.df.loc[index, 'hpi_<-2.0'] = hpi\n",
    "        hpi5.append(sum(i < -2.5 for i in sw))\n",
    "        # self.df.loc[index, 'hpi_<-2.5'] = hpi \n",
    "    df['hpi_<-1.5_frac'] = hpi0\n",
    "    df['hpi_<-2.0_frac'] = hpi1\n",
    "    df['hpi_<-2.5_frac'] = hpi2\n",
    "    df['hpi_<-1.5'] = hpi3\n",
    "    df['hpi_<-2.0'] = hpi4\n",
    "    df['hpi_<-2.5'] = hpi5\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "auburn-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amino_acid_analysis(df):\n",
    "    for res in RESIDUES:\n",
    "        df['fraction_'+res] = df['Seq'].str.count(res) / df['Seq'].str.len()\n",
    "    df['length'] = df['Seq'].str.len()\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    #for index, row in self.df.iterrows():\n",
    "        seq = row['Seq']   \n",
    "        seqanalysis = ProteinAnalysis(seq)\n",
    "        acidist = seqanalysis.get_amino_acids_percent() \n",
    "        df.loc[index, 'IEP'] = seqanalysis.isoelectric_point()\n",
    "        if 'X' not in seq and 'B' not in seq:\n",
    "            df.loc[index, 'molecular_weight'] = seqanalysis.molecular_weight()\n",
    "        if 'U' not in seq and 'X' not in seq and 'B' not in seq:\n",
    "            df.loc[index, 'gravy'] = seqanalysis.gravy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "romance-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_biochemical_combinations(df):\n",
    "    df = amino_acid_analysis(df)\n",
    "    df = df.assign(Asx=df['fraction_D'] + df['fraction_N'])\n",
    "    df = df.assign(Glx=df['fraction_E'] + df['fraction_Q'])\n",
    "    df = df.assign(Xle=df['fraction_I'] + df['fraction_L'])\n",
    "    df = df.assign(Pos_charge=df['fraction_K'] + df['fraction_R'] + df['fraction_H'])\n",
    "    df = df.assign(Neg_charge=df['fraction_D'] + df['fraction_E'])\n",
    "    df = df.assign(Aromatic=df['fraction_F'] + df['fraction_W'] + df['fraction_Y'] + df['fraction_H'])\n",
    "    df = df.assign(Alipatic=df['fraction_V'] + df['fraction_I'] + df['fraction_L'] + df['fraction_M'])\n",
    "    df = df.assign(Small=df['fraction_P'] + df['fraction_G'] + df['fraction_A'] + df['fraction_S'])\n",
    "    df = df.assign(Hydrophilic=(df['fraction_S'] + df['fraction_T'] + df['fraction_H'] + \n",
    "                                df['fraction_N'] + df['fraction_Q'] + df['fraction_E'] +\n",
    "                                df['fraction_D'] + df['fraction_K'] + df['fraction_R']))\n",
    "    df = df.assign(Hydrophobic= (df['fraction_V'] + df['fraction_I'] + df['fraction_L'] +\n",
    "                                 df['fraction_F'] + df['fraction_W'] + df['fraction_Y'] +\n",
    "                                 df['fraction_M']))\n",
    "\n",
    "    # Added in version 2\n",
    "    for dimer in ['GV', 'VG', 'VP', 'PG', 'FG', 'RG', 'GR', 'GG', 'YG', 'GS', 'SG', 'GA', 'GF', 'GD', 'DS']:\n",
    "        df[dimer] = df['Seq'].str.count(dimer)\n",
    "    df = df.assign(alpha_helix=df['fraction_V'] + df['fraction_I'] + df['fraction_Y'] + df['fraction_F']\n",
    "                  + df['fraction_W'] + df['fraction_L'])\n",
    "    df = df.assign(beta_turn=df['fraction_N'] + df['fraction_P'] + df['fraction_G'] + df['fraction_S'])\n",
    "    df = df.assign(beta_sheet=df['fraction_E'] + df['fraction_M'] + df['fraction_A'] + df['fraction_L'])\n",
    "    #Calculates the aromaticity value of a protein according to Lobry, 1994. \n",
    "    # It is simply the relative frequency of Phe+Trp+Tyr.\n",
    "    df = df.assign(aromaticity=df['fraction_F'] + df['fraction_W'] + df['fraction_Y'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ordinary-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lowcomplexity_features(df):\n",
    "    n_window = 20\n",
    "    cutoff = 7       \n",
    "    n_halfwindow = int(n_window / 2)        \n",
    "    lcs_lowest_complexity = list()\n",
    "    lcs_scores = list()\n",
    "    lcs_fractions = list()\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    #for index, row in df.iterrows():            \n",
    "        # Determine low complexity scores\n",
    "        seq = str(row['Seq'])\n",
    "        lcs_acids = list()\n",
    "        sig = list()\n",
    "\n",
    "        # New\n",
    "        lc_bool = [False] * len(seq)\n",
    "        for i in range(len(seq)):\n",
    "            if i < n_halfwindow:\n",
    "                peptide = seq[:n_window]        \n",
    "            elif i+n_halfwindow > int(len(seq)):\n",
    "                peptide = seq[-n_window:]        \n",
    "            else:\n",
    "                peptide = seq[i-n_halfwindow:i+n_halfwindow]       \n",
    "            complexity = (len(set(peptide)))\n",
    "            if complexity <= 7:\n",
    "                for bool_index in (i-n_halfwindow, i+n_halfwindow):\n",
    "                    try:\n",
    "                        lc_bool[bool_index] = True\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                lcs_acids.append(seq[i])\n",
    "            sig.append(complexity)            \n",
    "        # Adding low complexity scores to list\n",
    "        low_complexity_list = pd.DataFrame({'bool':lc_bool, 'acid':list(seq)}, index=None)\n",
    "        lcs_lowest_complexity.append(min(sig))\n",
    "        lcs_scores.append(len(low_complexity_list.loc[low_complexity_list['bool'] == True]))\n",
    "        lcs_fractions.append(len(low_complexity_list.loc[low_complexity_list['bool'] == True]) / len(seq))\n",
    "        low_complexity_list = pd.DataFrame({'bool':lc_bool, 'acid':list(seq)}, index=None)\n",
    "        if len(lcs_acids) >= n_window:\n",
    "            for i in RESIDUES:\n",
    "                df.loc[index ,i+'_lcscore'] = (len(low_complexity_list.loc[\n",
    "                    (low_complexity_list['bool'] == True) &\n",
    "                    (low_complexity_list['acid'] == i)])\n",
    "                )\n",
    "                df.loc[index ,i+'_lcfraction'] = (len(low_complexity_list.loc[\n",
    "                    (low_complexity_list['bool'] == True) & \n",
    "                    (low_complexity_list['acid'] == i)]) / len(lcs_acids)\n",
    "                )\n",
    "    df['lcs_fractions'] = lcs_fractions\n",
    "    df['lcs_scores'] = lcs_scores\n",
    "    df['lcs_lowest_complexity'] = lcs_lowest_complexity\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unique-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_ic50 = pd.read_csv(\"data/raw/AVP-IC50Pred_train.csv\")\n",
    "ha_avp = pd.read_csv(\"data/raw/HA_AVP.csv\")\n",
    "\n",
    "df = pd.concat([avp_ic50[['Sequence', 'MIC']], ha_avp], axis=0).drop_duplicates(['Sequence']).reset_index(drop=True)\n",
    "df = sequence_filtering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "renewable-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Seq', 'MIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "complicated-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>MIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAQRRGRVGRNPNQVGD</td>\n",
       "      <td>442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRILARIRQMMT</td>\n",
       "      <td>435.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Seq    MIC\n",
       "0  AAQRRGRVGRNPNQVGD  442.0\n",
       "1       HRILARIRQMMT  435.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "printable-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 712/712 [00:00<00:00, 1594.73it/s]\n",
      "100%|██████████| 712/712 [00:00<00:00, 867.44it/s]\n",
      "100%|██████████| 712/712 [00:02<00:00, 258.44it/s]\n"
     ]
    }
   ],
   "source": [
    "df = add_hydrophobic_features(df)\n",
    "df = add_biochemical_combinations(df)\n",
    "df = add_lowcomplexity_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "controversial-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Seq', 'MIC', 'HydroPhobicIndex', 'hpi_<-1.5_frac', 'hpi_<-2.0_frac',\n",
       "       'hpi_<-2.5_frac', 'hpi_<-1.5', 'hpi_<-2.0', 'hpi_<-2.5', 'fraction_A',\n",
       "       ...\n",
       "       'T_lcfraction', 'V_lcscore', 'V_lcfraction', 'W_lcscore',\n",
       "       'W_lcfraction', 'Y_lcscore', 'Y_lcfraction', 'lcs_fractions',\n",
       "       'lcs_scores', 'lcs_lowest_complexity'],\n",
       "      dtype='object', length=105)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "blank-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean_CDHIT_new_50_v2_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "diagnostic-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['HydroPhobicIndex'], axis=1).to_csv(\"data/raw/105_feature_ha_avp_ic50.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-crawford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"hrushi/human-predict.fasta\"\n",
    "rows = list()\n",
    "for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "    seqdict = dict()\n",
    "    seq = str(record.seq)\n",
    "    id = record.description.split('|')                \n",
    "    if id[0] == 'sp':\n",
    "        uniprot_id = id[1]\n",
    "        rows.append([uniprot_id, seq])\n",
    "    elif id[0] == 'tr':\n",
    "        uniprot_id = id[1]\n",
    "        rows.append([uniprot_id, seq])\n",
    "    else:\n",
    "        uniprot_id = id[0]\n",
    "        rows.append([uniprot_id, seq])                    \n",
    "db1 = pd.DataFrame(rows, columns=['uniprot_id', 'sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "db1.columns = ['Entry', 'Sequence']\n",
    "db1.drop_duplicates(['Sequence'], inplace=True)\n",
    "db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = pd.read_csv(\"hrushi/human-predict_prob_wo_properties_best_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2.columns = ['Sequence', 'Probability']\n",
    "db2.drop_duplicates(['Sequence'], inplace=True)\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3 = pd.read_csv(\"hrushi/CellReports_Prediction.xlsx - PSAP probabilities for human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3.columns = ['Entry', 'UniprotKB_ID', 'PSAP_score']\n",
    "db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "db4 = db1.merge(db2, how='inner', on='Sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "db4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3.Entry.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3 = db3.merge(db4, how='left', on='Entry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-creativity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-benefit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3.to_csv(\"hrushi/human-predict_properties_updated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-commerce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
