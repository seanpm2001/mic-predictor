{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enhanced-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import requests\n",
    "import pandas as pd\n",
    "search_url = 'https://www.ebi.ac.uk/pdbe/search/pdb/select?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valuable-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request_post(search_dict, number_of_rows=10):\n",
    "    \"\"\"\n",
    "    makes a post request to the PDBe API\n",
    "    :param dict search_dict: the terms used to search\n",
    "    :param number_of_rows: number or rows to return - initially limited to 10\n",
    "    :return dict: response JSON\n",
    "    \"\"\"\n",
    "    # make sure we get the number of rows we need\n",
    "    if 'rows' not in search_dict:\n",
    "        search_dict['rows'] = number_of_rows\n",
    "    # set the return type to JSON\n",
    "    search_dict['wt'] = 'json'\n",
    "\n",
    "    # do the query\n",
    "    response = requests.post(search_url, data=search_dict)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"[No data retrieved - %s] %s\" % (response.status_code, response.text))\n",
    "\n",
    "    return {}\n",
    "def format_sequence_search_terms(sequence, filter_terms=None):\n",
    "    \"\"\"\n",
    "    Format parameters for a sequence search\n",
    "    :param str sequence: one letter sequence\n",
    "    :param lst filter_terms: Terms to filter the results by\n",
    "    :return str: search string\n",
    "    \"\"\"\n",
    "    # first we set the parameters which we will pass to PDBe's search\n",
    "    params = {\n",
    "        'json.nl': 'map',\n",
    "        'start': '0',\n",
    "        'sort': 'fasta(e_value) asc',\n",
    "        'xjoin_fasta': 'true',\n",
    "        'bf': 'fasta(percentIdentity)',\n",
    "        'xjoin_fasta.external.expupperlim': '0.1',\n",
    "        'xjoin_fasta.external.sequence': sequence,\n",
    "        'q': '*:*',\n",
    "        'fq': '{!xjoin}xjoin_fasta'\n",
    "    }\n",
    "    # we make sure that we add required filter terms if they aren't present\n",
    "    if filter_terms:\n",
    "        for term in ['pdb_id', 'entity_id', 'entry_entity', 'chain_id']:\n",
    "            filter_terms.append(term)\n",
    "        filter_terms = list(set(filter_terms))\n",
    "        params['fl'] = ','.join(filter_terms)\n",
    "\n",
    "    # returns the parameter dictionary\n",
    "    return params\n",
    "def run_sequence_search(sequence, filter_terms=None, number_of_rows=100):\n",
    "    \"\"\"\n",
    "    Runs a sequence search and results the results\n",
    "    :param str sequence: sequence in one letter code\n",
    "    :param lst filter_terms: terms to filter the results by\n",
    "    :param int number_of_rows: number of results to return\n",
    "    :return lst: List of results\n",
    "    \"\"\"\n",
    "    search_dict = format_sequence_search_terms(sequence=sequence, filter_terms=filter_terms)\n",
    "    response = make_request_post(search_dict=search_dict, number_of_rows=number_of_rows)\n",
    "    results = response.get('response', {}).get('docs', [])\n",
    "    print('Number of results {}'.format(len(results)))\n",
    "\n",
    "    # we now have to go through the FASTA results and join them with the main results\n",
    "\n",
    "    raw_fasta_results = response.get('xjoin_fasta').get('external')\n",
    "    fasta_results = {} # results from FASTA will be stored here - key'd by PDB ID and Chain ID\n",
    "\n",
    "    # go through each FASTA result and get the E value, percentage identity and sequence from the result\n",
    "\n",
    "    for fasta_row in raw_fasta_results:\n",
    "        # join_id = fasta_row.get('joinId')\n",
    "        fasta_doc = fasta_row.get('doc', {})\n",
    "        percent_identity = fasta_doc.get('percent_identity')\n",
    "        e_value = fasta_doc.get('e_value')\n",
    "        return_sequence = fasta_row.get('return_sequence_string')\n",
    "        pdb_id_chain = fasta_doc.get('pdb_id_chain').split('_')\n",
    "        pdb_id = pdb_id_chain[0].lower()\n",
    "        chain_id = pdb_id_chain[-1]\n",
    "        join_id = '{}_{}'.format(pdb_id, chain_id)\n",
    "        fasta_results[join_id] = {'e_value': e_value,\n",
    "                                  'percentage_identity': percent_identity,\n",
    "                                  'return_sequence': return_sequence}\n",
    "    # now we go through the main results and add the FASTA results\n",
    "    ret = [] # final results will be stored here.\n",
    "    for row in results:\n",
    "        pdb_id = row.get('pdb_id').lower()\n",
    "        chain_ids = row.get('chain_id')\n",
    "        for chain_id in chain_ids:\n",
    "            search_id = '{}_{}'.format(pdb_id, chain_id)\n",
    "            entry_fasta_results = fasta_results.get(search_id, {})\n",
    "            # we will only keep results that match the search ID\n",
    "            if entry_fasta_results:\n",
    "                row['e_value'] = entry_fasta_results.get('e_value')\n",
    "                row['percentage_identity'] = entry_fasta_results.get('percentage_identity')\n",
    "                row['result_sequence'] = entry_fasta_results.get('return_sequence_string')\n",
    "\n",
    "                ret.append(row)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/avani_mahadik/Documents/avani/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amber-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results 90\n",
      "Number of results 0\n",
      "Number of results 0\n",
      "Number of results 2\n",
      "Number of results 90\n",
      "Number of results 80\n",
      "Number of results 80\n",
      "Number of results 100\n",
      "Number of results 100\n",
      "Number of results 100\n",
      "Number of results 100\n",
      "Number of results 100\n",
      "Number of results 100\n",
      "Number of results 100\n",
      "Number of results 100\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "with open('ha.txt','r') as fh:\n",
    "    for line in fh:\n",
    "        sequence_to_search = line.strip()\n",
    "\n",
    "        filter_list = ['pfam_accession', 'pdb_id', 'molecule_name',\n",
    "                       'uniprot_accession_best','resolution','mutation','has_modified_residues']\n",
    "\n",
    "        first_results = run_sequence_search(sequence_to_search, filter_terms=filter_list)\n",
    "        first_results = [sequence_to_search]+first_results\n",
    "        results_list.append(first_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "young-queue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "progressive-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_lists_to_strings(results):\n",
    "    \"\"\"\n",
    "    updates lists to strings for loading into Pandas\n",
    "    :param dict results: dictionary of results to process\n",
    "    :return dict: dictionary of results\n",
    "    \"\"\"\n",
    "    for row in results:\n",
    "        for data in row:\n",
    "            if type(row[data]) == list:\n",
    "                # if there are any numbers in the list change them into strings\n",
    "                row[data] = [str(a) for a in row[data]]\n",
    "                # unique and sort the list and then change the list into a string\n",
    "                row[data] = ','.join(sorted(list(set(row[data]))))\n",
    "\n",
    "    return results\n",
    "\n",
    "def pandas_dataset(list_of_results):\n",
    "    df_dict = {}\n",
    "    for res in list_of_results:\n",
    "        query_seq = res[0]\n",
    "        results = change_lists_to_strings(res[1:])  # we have added our function to change lists to strings\n",
    "        df = pd.DataFrame(results)\n",
    "        df_dict[query_seq] = df\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opened-calgary",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_dict = pandas_dataset(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "proved-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(df_dict, query):\n",
    "    return {seq: df.query(query) for seq, df in df_dict.items() if not df.empty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "lonely-effect",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict2 = apply_filter(df_dict, 'percentage_identity>50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Search_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-update",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
